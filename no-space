Basel Committee  on Banking Supervision
 Regulatory Consistency Assessment Programme
(RCAP) Handbook for Jurisdictional Assessments
 March 2018

This publication is available on the BIS website (www.bis.org).

©
 Bank for International Settlements 2018. All rights reserved. Brief excerpts may be reproduced or translated provided the source is stated.
 ISBN 978-92-9259-144-1 (online)

Contents Foreword ............................................................................................................................................................................................... 1 Glossary ................................................................................................................................................................................................ 2
1.
 Introduction to RCAP consistency assessments ................................................................................................. 3

2.
 Preparatory phase........................................................................................................................................................... 5

3
 Assessment phase ........................................................................................................................................................ 11

4
 Review phase .................................................................................................................................................................. 22

5
 Publication and follow-up of RCAP assessments ............................................................................................. 24

6.
 RCAP-Capital: assessments of Basel risk-based capital standards ............................................................ 27

7.
 RCAP-LCR ......................................................................................................................................................................... 29

8.
 RCAP-SIB .......................................................................................................................................................................... 33

9.
 RCAP-NSFR ...................................................................................................................................................................... 36

10.
 RCAP-Large exposures................................................................................................................................................ 38
 RCAP Jurisdictional Assessments Handbook
 iii

Foreword The RCAP Handbook for Jurisdictional Assessments (the Handbook) contains guidance and principles for RCAP Assessment Teams, assessed jurisdictions and experts seeking background information on RCAP issues and implementation topics. In particular, it describes the RCAP process for conducting jurisdictional assessments. From a governance perspective, jurisdictional assessments are closely supervised by the RCAP Peer Review Board (PRB), with feedback from the Basel Committee’s (the Committee’s) Supervision and Implementation Group (SIG). All assessments are finalised by the Basel Committee. The SIG is a key part of this process as it is responsible for monitoring the implementation of the Basel framework through the RCAP. The Handbook presents a general framework as well as specific methodologies for assessing a regulatory framework’s quality and consistency, eg for assessing the materiality of deviations, and contains examples of analytical templates and tools that are typically used in jurisdictional assessments. The assessment methodology is sufficiently general to accommodate differences in structural and institutional factors across jurisdictions. The Handbook was prepared by the implementation team of the Basel Committee Secretariat and reviewed and approved by the SIG and the Committee. The Handbook is a flexible compendium in that guidance and principles will be revised or elaborated further as the RCAP evolves. It will be updated periodically based on lessons learnt from jurisdictional assessments and SIG discussions. It is also a reference for jurisdictions intending to carry out their own implementation reviews. As such, it could also help for training and preparation purposes. This version of the Handbook supersedes the previous version published by the Committee in March 2016.
 RCAP Jurisdictional Assessments Handbook

1

Glossary ALA
 Advanced Liquidity Approach
 D-SIB
 Domestic systemically important bank
 FAQ
 Frequently Asked Question
 FSAP
 Financial Sector Assessment Program
 FSB
 Financial Stability Board
 G-SIB
 Global systemically important bank
 HQLA
 High-quality liquid assets
 LCR
 Liquidity Coverage Ratio
 LEX
 Large exposures framework
 NSFR
 Net Stable Funding Ratio
 PDG
 Policy Development Group
 PRB
 Peer Review Board
 RCAP
 Regulatory Consistency Assessment Programme
 RSF
 Required stable funding
 RWA
 Risk-weighted assets
 SIG
 Supervision and Implementation Group
 WGL
 Working Group on Liquidity

2
 RCAP Jurisdictional Assessments Handbook

1.
 Introduction to RCAP consistency assessments

1.1
 Introducing the RCAP
 A key component of the Basel Committee’s work is to ensure strong regulatory regimes and effective supervisory systems across its member jurisdictions. Public confidence in banks, prudential ratios, and a level playing field cannot be assured unless the Basel standards are consistently adopted and implemented. The lessons of the recent financial crisis have underscored the need for full, timely and consistent implementation of the Basel standards. Recognising the importance of implementation, the Committee established the RCAP in 2012. All Basel member jurisdictions contribute to the RCAP and participate in its monitoring and assessments. The purpose of the programme is to ensure the full, timely and consistent implementation of the Basel framework and thus contribute to global financial stability. The RCAP supports the Financial Stability Board’s (FSB) Coordination Framework for Monitoring the Implementation of Agreed G20/FSB Financial Reforms. 1 The RCAP also complements the Financial Sector Assessment Program (FSAP) of the International Monetary Fund and World Bank, which, among other things, assesses compliance with the Basel Committee’s Core principles for effective banking supervision 2 . The RCAP focuses on regulatory implementation of the Basel framework in terms of consistency and completeness, while the FSAP assessment of the Basel Core Principles takes into account the full range of supervisory practices and is carried out in the context of a wider financial stability risk analysis. In general, the RCAP consists of two distinct but complementary parts. The first is based on selfreporting and monitors the timely adoption of Basel standards. The second assesses the consistency and completeness of the adopted standards. The second part has two strands: jurisdictional peer reviews and thematic assessments of regulatory outcome. 3 More information on the programme’s structure, together with all published RCAP reports, is available at www.bis.org/bcbs/implementation.htm. The RCAP is overseen by the SIG, which is responsible for developing and maintaining the assessment methodology described in this Handbook, with support from the Secretariat. The Basel Committee has the final responsibility for approving the assessment methodology, as well as all assessment reports and interpretations of its standards.

1.2
 RCAP consistency assessments – jurisdictional peer reviews
 This Handbook focuses on the jurisdictional peer reviews. These reviews assess how far domestic regulations in each member jurisdiction are aligned with the minimum requirements defined by the Committee. The aim of these reviews is to promote full and consistent adoption of the internationally agreed Basel framework by identifying provisions in the domestic regulations, as applicable to internationally active banks, that are not in line with the letter and spirit of the relevant Basel standards. This is complemented by materiality analysis, which highlights the current and potential impact of any gaps in the regulations on financial stability and the international level playing field. One key objective is to help member jurisdictions to undertake the reforms needed to improve the alignment of national regulations with the internationally agreed Basel standards. The focus of the assessments is on domestic

1
 See www.fsb.org/what-we-do/implementation-monitoring/.

2
 Core principles for effective banking supervision, Basel Committee on Banking Supervision, September 2012, www.bis.org/publ/bcbs230.htm.

3
 More information on the thematic assessments is available at www.bis.org/bcbs/implementation/rcap_thematic.htm. These assessments focus on regulatory outcomes and seek to ensure that the prudential ratios calculated by banks are consistent across banks and jurisdictions. These assessments are not discussed further in this Handbook.
 RCAP Jurisdictional Assessments Handbook

3

regulations; examining issues relating to the functioning of regulatory frameworks and effectiveness of implementation and supervisory frameworks is not the purpose of the RCAP. The RCAP consistency assessments have four distinct phases: (i) the preparatory phase; (ii) offand on-site assessment; (iii) the review phase; and (iv) publication and follow-up. These are discussed in Sections 2–5. Chart 1 illustrates the main components of each phase. This Handbook is drafted mainly on the basis of a single Assessment Team reviewing a single jurisdiction (a “jurisdictional assessment”). However, these general considerations also apply to crossjurisdictional assessments (ie a single Assessment Team reviewing more than one jurisdiction). More specific guidance for reviewing particular standards, including where the RCAP has adopted a crossjurisdictional assessment model, is provided in Sections 6–10.
 Phases of an RCAP consistency assessment
 Preparatory phase

• Team composition
• Pre-assessment scoping
• Self-assessment
• Data-gathering
• Desk-based review

4
 Assessment phase

• Off-site and onsite review
• Identification of gaps
• Drafting of report
• Discussions with authorities on gaps and recommendations
 Chart 1
 Review phase
 Follow-up phase

• Peer review of draft report by Review Team, SIG and Basel Committee
• Discussion on follow-up

• Finalisation, publication and dissemination of report
• Post-assessment follow-up of recommendations
 RCAP Jurisdictional Assessments Handbook

2.
 Preparatory phase

2.1
 RCAP assessment questionnaires
 Jurisdictions participating in an RCAP assessment will start working on an RCAP self-assessment questionnaire well ahead of the actual assessment by an Assessment Team. When questionnaires are completed on schedule, jurisdictions can start the necessary data collection for the Assessment Team at an early stage, reducing time pressures on regulatory and bank staff. The relevant Basel Committee policy working groups are responsible for preparing selfassessment questionnaires. The RCAP questionnaires for the Basel risk-based capital standards, the Liquidity Coverage Ratio (LCR), the January 2015 Pillar 3 standards, the Net Stable Funding Ratio (NSFR) and the large exposures framework are available on the Basel Committee website. 4

2.2
 Establishing the RCAP teams

2.2.1
 Team Leader
 The RCAP Team Leader is selected by the PRB, taking into account any recommendation from the Committee’s Head of Basel III Implementation. Team Leaders are typically Basel Committee members or officials of similar seniority from Basel Committee member authorities. The Team Leader’s role is to manage the RCAP assessment, supported by the Secretariat. 5 As such, the Team Leader will manage and coordinate the off-site work of the Assessment Team and lead the on-site mission. The Team Leader will be responsible for delivering the RCAP assessment report, and hence for informing the Basel Committee of the outcome of the review. To fulfil this role, the Team Leader is expected to (i) plan and support the work of the Assessment Team and Review Team as much as possible; and (ii) exercise an oversight role, with cooperation and assistance from the Secretariat, ensuring that the Assessment Team’s deliberations focus on substance over form and remain within the supervisory scope of the review. Both roles are crucial to ensure the quality of the assessment delivered by the assessors. The Team Leader will liaise closely with the Secretariat on all strategic and policy issues relating to the assessment.

2.2.2
 Assessment Team
 The Assessment Team conducts the off-site and on-site assessment, drafts the assessment report and determines the preliminary assessment grades. It comprises regulatory and supervisory experts drawn from the organisations of Committee members or observers. 6 The Secretariat, in consultation with the Team Leader, will recommend an Assessment Team, for approval by the PRB. The size and composition of the team will vary depending upon the scope of the assessment and the jurisdiction undergoing an assessment. In composing the team, the Secretariat and the PRB should ensure that the Assessment Teams are independent from the assessed jurisdiction so as to avoid any potential conflict of interest. The main objectives for team selection will be: (i) obtaining high-quality expertise to cover all components of the standard being assessed; (ii) ensuring that selected members could work both as primary and secondary reviewers within the team, ensuring “four eyes” for each assessed component; and

4
 See www.bis.org/bcbs/implementation/rcap_role.htm.

5
 In practice, Team Leaders are often supported by one or two members of their own staff, although this is at the Team Leader’s discretion. The Secretariat works in close coordination with the staff of the Team Leader’s institution and maintains primary responsibility for the administrative management of the RCAP.

6
 Including the Basel Consultative Group.
 RCAP Jurisdictional Assessments Handbook

5

(iv) achieving appropriate geographic diversity and, where possible, language skills to assist in verifying any translations provided. Once the team is selected, it will be formally approved by the PRB. To help in the selection of assessors and ensure continued availability of high-quality experts, the Secretariat maintains a roster of experts. The Secretariat will periodically ask the SIG, the Basel Consultative Group and other relevant working groups to update the roster to ensure that the appropriate expertise is available for upcoming assessments. All Committee members are expected to provide resources to support RCAP assessment work.

2.2.3
 Review Team
 Alongside the establishment of the Assessment Team, the PRB will also set up a Review Team for each assessment, typically comprising four members. The Review Team will be drawn from the SIG and other Committee working groups (notably the Policy Development Group, or PDG), and will also include a senior member of the Secretariat. 7 The Secretariat and the PRB should ensure that reviewers are independent from the assessed jurisdiction and Assessment Team members. The Review Team reviews the draft report before it goes to the PRB for final review. The Review Team also reports to the SIG when the SIG is informed by the Team Leader about material findings or policy issues arising from the RCAP assessment. During the assessment, the Review Team can be consulted on interpretative issues. If the Assessment Team and the Review Team cannot reach a common understanding, the issue is escalated to the PRB.

2.2.4
 Peer Review Board
 The PRB comprises the Chair of the Basel Committee, the Chair of the SIG and the Committee’s Secretary General. However, in the case that more than one of these members has an actual or potential conflict of interest with the jurisdiction being assessed, a separate Peer Review Board will be established. This will generally comprise Basel Committee members with no link to the jurisdictions being assessed. The PRB supervises the assessment process and approves the RCAP Team Leaders, Assessment Teams and Review Teams. In approving the teams, the PRB ensures that they enjoy independence with respect to the assessed jurisdiction. During the assessment, the PRB can be consulted on issues related to assessment methodology. If needed, the PRB can propose amendments to the assessment methodology to the SIG for review and approval for submission to the Basel Committee. Interpretative issues can also be escalated to the PRB by reference of the Head of Basel III Implementation. The PRB approves the submission of the assessment report to the Basel Committee.

2.2.5
 Secretariat support
 Each RCAP assessment will be supported by the Basel Committee Secretariat. Member(s) of the Secretariat support the Team Leader, the Assessment Team and the Review Team as well as the authorities in the jurisdiction being assessed. In addition, the Committee’s Head of Basel III Implementation should work closely with the relevant authorities and the Team Leader on the RCAP scope and the strategic and policy issues as they may arise so as the assessment progresses smoothly and maintains its rigour. To avoid any conflict of interest, the Head of Basel III Implementation does not take part in the validation effort by the Review Team or the PRB. This individual’s role is to act as a facilitator between the RCAP assessment team and the

7

6
 Typically a Deputy Secretary General, though, to avoid any conflict of interest, not the Head of Basel III Implementation. See also Section 2.2.5.
 RCAP Jurisdictional Assessments Handbook

assessed jurisdiction, to help ensure the consistency and completeness of each RCAP, and to assist on technical or policy matters as they may arise. The Head of Basel III Implementation also supports the PRB.

2.3
 Confidentiality arrangements
 The Assessment Team, Review Team, SIG and PRB will follow the confidentiality arrangements of the Committee. Preliminary assessment findings and grades are particularly sensitive and should be treated as confidential until they have been discussed and approved by the Committee. The Assessment Team, Team Leader and any members of staff of the Team Leader’s organisation supporting the assessment
(Supporting Members) will be subject to a specific RCAP confidentiality agreement that is agreed with the assessed jurisdiction.

2.4
 Scoping Note: agreeing the scope and time line
 The Team Leader and the assessed jurisdiction will agree on a Scoping Note before the start of the assessment work. This Note specifies the scope of the assessment (ie the standards and RCAP components to be assessed), any specific details of the assessment process not covered by the general RCAP methodology, the sample of banks to be used for materiality testing and the time line. The Scoping Note is shared with the PRB and the Review Team for information. The documents to be assessed for each RCAP are listed in Sections 6–10. These generally include the relevant Basel standards and associated published Frequently Asked Questions (FAQs). The Basel standards are assessed line by line. FAQs are used only to clarify the intention and interpretation of the standards where the original text is unclear. They are not assessed in isolation. Therefore, an FAQ cannot be cited as the sole source of a deviation, but rather is assessed only in conjunction with the relevant Basel text that it clarifies. Similarly, direct implementation of an FAQ in domestic regulations is not treated as super-equivalent. Section 2.6 describes the process for assessing revised Basel standards where a jurisdiction has implemented a more recent Basel standard in advance of the implementation deadline. The scope of the assessment may also include items listed for follow-up in earlier RCAP assessments, or other components that an assessed jurisdiction wishes to be reviewed again (eg if it has made several changes to improve the compliance of its regulations). Generally, all items listed for followup in previous assessment reports should be included in the scope of subsequent assessments (see Section
5.2.1). This should be discussed by the Team Leader and the assessed jurisdiction at an early stage, to ensure that Assessment Teams have the appropriate expertise. Normally, the sample of banks should constitute a minimum of 60% of the banking assets 8 of the banks in the jurisdiction that are subject to the Basel standard (or standards) under review (eg the Basel risk-based capital framework). The focus of the Basel framework is on internationally active banks, and therefore, the materiality assessment should, in principle, cover the internationally active banks in the jurisdiction. However, other banks may also be included, for instance domestic systemically important banks (D-SIBs). The sample should be representative of the various types of bank operating in the jurisdiction. The Secretariat may make recommendations on the choice of coverage of banks in a manner that will avoid potential selection bias on the part of the Assessment Team or the jurisdiction being assessed. A high-level time line for a typical RCAP assessment is provided in Table 1. Each RCAP generally starts around nine months before the publication of the report, with roughly three months in each of the

8
 For this purpose, banking assets includes both on-balance sheet and off-balance sheet assets. The relevant measure will be total exposures as calculated for the purpose of complying with the Basel leverage ratio standard.
 RCAP Jurisdictional Assessments Handbook

7

preparatory, assessment and review phases. The month in which publication is planned is made public on the Committee’s website and in implementation progress reports to the G20 and FSB. The detailed time line for each assessment will be formulated by the Team Leader and the Secretariat in agreement with the assessed jurisdiction. An important aspect of this is the cut-off date. The Assessment Team will take into account regulations and rectifications, provided that these are issued before the assessment’s cut-off date. The cut-off date should ensure that there is sufficient time for Assessment Teams to assess the consistency of the finalised regulations before submitting the report to the Review Team. Adjustments may be required to the time line as the assessment progresses. Minor adjustments can be agreed between the Team Leader and the assessed jurisdiction. The process for handling longer delays is set out in Section 2.5. Jurisdictions whose regulations are not published in English should also take into account the time needed to prepare translations, particularly during the preparatory phase.

8
 RCAP Jurisdictional Assessments Handbook

Illustrative assessment timeline Initiator
 Table 1 Activity
 Time to RCAP publication
 PRB
 Selection of Team Leader (see Section 2.2.1)

12–9 months
 Team Leader and Secretariat
 Establishing the Assessment Team and a Review Team (see Sections 2.2.2 and
2.2.3).

9 months
 Secretariat
 Draft the Scoping Note (see Section 2.4). The Scoping Note is discussed and agreed between the Team Leader and the assessed jurisdiction and transmitted to the Review Team and the PRB for information.

9–6 months
 Assessed jurisdiction
 Submit the completed RCAP assessment questionnaire, data and information on self-identified gaps to Secretariat (see Section 2.1).

8–6 months
 Assessment Team and assessed jurisdiction
 Off-site assessment by Assessment Team (see Section 3.1). Exchange between the Assessment Team and the assessed jurisdiction on technical matters.

6–4 months
 Team meeting to discuss and agree preliminary findings.
 Assessment Team
 Assessed jurisdiction
 Subsequently, first draft of the assessment report prepared by the Assessment Team on the state of regulatory regime; material/policy/special issues discussed by the Team Leader with the jurisdiction and the Head of Basel III Implementation; additional data and information requests sent to the jurisdiction. If required, Team Leader informs or discusses emerging issues with the Review Team and the PRB. Additional data, information and clarifications sent to Assessment Team.

6–4 months

4–3.5 months
 Off-site work and report drafting continues. Assessment Team
 Assessed jurisdiction
 On-site assessment (see Section 3.2). Draft RCAP report and its findings along with the preliminary assessment grades discussed and presented. Draft report left for comments with the jurisdiction. Feedback provided on draft report. Cut-off date. Deadline for any changes to regulations.

3.5–3 months

3–2.5 months
 Assessment Team
 Draft report revised and circulated to the Review Team for comments.

2.5–2 months
 Review Team
 Review report and provides feedback to Team Leader and Assessment Team
(see Section 4.1).

2–1.5 months
 Team Leader and Secretariat
 RCAP report finalised by the Team Leader. Submitted by the Secretariat for review by SIG and clearance by the PRB (see Sections 4.1 and 4.2).

1 month
 Secretariat
 Views and recommendations by SIG are shared with the PRB (see Section 4.1).

1–0.5 months
 Secretariat
 Report submitted to the BCBS for discussion and approval (see Section 4.2).

0.5 months
 Basel Committee
 Report published. Secretariat to follow up on progress (see Section 5).

0 months

2.5
 Principles and process for handling delays to an RCAP jurisdictional assessment report
 Since the adoption of the RCAP, there have been a limited number of situations in which a Committee discussion of a draft jurisdictional assessment report has been delayed beyond the timetable agreed in the Scoping Note to accommodate domestic circumstances. Ordinarily, when there is no delay, amendments that are made after the scheduled cut-off date should be monitored via the RCAP assessment follow-up programme (see Section 5.2.2). In these cases, such amendments do not affect the published assessment findings. In exceptional cases, however, a small delay can materially improve the prudential outcome.
 RCAP Jurisdictional Assessments Handbook

9

When a member jurisdiction plans to amend its domestic regulations but cannot do so in the scheduled expected timeframe, or faces extreme and unforeseen challenges in completing the RCAP assessment in the time scheduled, the member can formally request a delay in the cut-off date and the date for submission of the assessment report to the Committee. Responsibility for recommending a delay to the Committee rests with the PRB. The principal considerations the PRB should take into account are:
•
 Promoting better outcomes: would the proposed amendments be binding, lead to a materially better prudential outcome and promote full and consistent implementation of the Basel framework?

•
 Making a case for a delay: is there a sufficiently strong and specific reason for a delay related to local circumstances such as the complex nature of the proposed amendment, of institutional factors or of rule-making processes? Are there compelling reasons why it would be better for these amendments to be made before the cut-off date as opposed to afterwards?

•
 Limiting the delay and the scope of the amendments: ordinarily, the extension of the assessment cut-off date and the consequent delay in a Committee discussion should be limited to one quarterly Committee meeting cycle. Can the proposed amendments be achieved without significantly broadening the scope of the assessment?

•
 Meeting public commitments: can a delay sufficient to achieve a materially better prudential outcome be granted without breaching any public commitments made by the Committee?

2.6
 Approach for assessing revised Basel standards
 When a jurisdiction has implemented the revised Basel standard, or expects to finalise its implementation by the cut-off date of the assessment, it can request the assessment to be based on the revised Basel standard instead of the existing (and to-be-superseded) Basel standard. Once the agreed implementation deadline of a revised Basel standard has passed, the jurisdictional RCAP assessments will automatically be based on the revised Basel standard. Basel standards that are under revision or in consultation will not be part of the scope of a jurisdictional RCAP assessment.

10
 RCAP Jurisdictional Assessments Handbook

3
 Assessment phase
 The role of the Assessment Team is to assess a jurisdiction’s compliance with Basel standards. Individual assessors review specific areas, based on their respective expertise, which feeds into an overall assessment of compliance for the respective jurisdiction. Assessors work based on a four-eyes principle (ie two Assessment Team members covering the same area, one acting as primary reviewer and the other as a secondary reviewer). Assessors will interact with officials in the assessed jurisdiction, especially during the on-site assessment. The Assessment Team is collectively responsible for proposing grades for individual components and the overall grade. Assessment Team members will be responsible for delivering highquality input for the RCAP assessment report. The work of the Assessment Team will be coordinated by the Team Leader with the assistance of the Secretariat.

3.1
 Off-site assessment
 A process for rigorous off-site review is based on work undertaken by primary and secondary assessors and active use of conference calls and face-to-face discussions to ensure interaction among the Assessment Team members. The RCAP uses a limited four-eyes review principle. The primary assessor will identify those parts of the domestic rules that are clearly compliant with the Basel standards while seeking to identify, without further evaluation, those parts that are super-equivalent, and to identify for further consideration those parts that may be sub-equivalent. When considering whether a provision is sub-equivalent, the primary assessor should apply a high standard of proof: anything not clearly compliant or super-equivalent should be flagged. The second assessor focuses on the work of the primary assessor and does not normally need to review the domestic regulation in its entirety. The second assessor reviews the list of potential gaps and considers whether any items should be removed. As an example: the language differs between the local and Basel texts, but the local text achieves the same outcome (or close enough to the same outcome to make no practical difference). The second assessor’s work should result in a shorter list of potential subequivalences. This list is what goes back to the jurisdiction for further analysis and data collection. The primary assessor should take the lead on determining the data necessary, where relevant, to estimate the materiality of a divergence. The secondary assessor should assist, particularly for those items considered potentially material and on issues requiring the use of expert judgment. At this stage, assessors are encouraged to err on the side of including issues and seeking further clarification where they are unsure. The four-eyes review process should ensure that the focus of the RCAP is to identify substantive issues rather than narrow wording differences. Assessors should pay careful attention that findings are clearly substantiated and explained in the report, and supported by data where available. Assumptions used to underpin the materiality assessment should be carefully explained. While a word-for-word comparison can be the starting point of the assessment – as differences in the choice of words may have a material effect – assessors should also take a step back and consider not only whether the assessed jurisdiction achieves the goals of the text but also the practical effect of deviations and the broader context of the assessment. Questions that assessors should ask themselves include notably: “Is the wording difference expected to lead to a substantially different outcome in practice?” and “How substantial is the impact compared with other findings in the assessment and in previous RCAP assessments?”. Maintaining a focus on substance over form should be a key element of the Team Leader’s role during the assessment. Also, the Review Team could be asked by the PRB to provide an opinion specifically on how this guidance to focus on substance has been met and is reflected in the draft RCAP report, eg by considering the proportionality between the identified deviations and the grades and whether the assessment is balanced and sufficiently supported by analysis and consistent with previous assessments.
 RCAP Jurisdictional Assessments Handbook

11

Typically, one physical meeting of the Assessment Team takes place ahead of the on-site visit. While the Team Leader and the Assessment Team should consider a work mode that is as efficient as possible using e-mail, teleconferences, videoconferences or other virtual meetings, and carefully consider whether there is a need for such a team meeting, it should be ensured that the decision not to organise a face-to-face meeting would not have detrimental effects on the efficacy, quality and consistency of the assessment. The off-site assessment should, at a minimum, result in a tentative list of deviations, additional data and clarification requests to be sent to the assessed jurisdiction for discussion ahead of the on-site assessment.

3.2
 On-site assessment
 On-site reviews are the best way of obtaining a correct understanding of issues related to the adoption and implementation of Basel standards identified during the off-site assessment. They involve face-toface exchanges with relevant experts and the authorities responsible for the transposition of Basel provisions into domestic regulations. As a general principle, on-site reviews are expected to be conducted as part of jurisdictional assessments. They may also be used in cross-jurisdictional assessments. The length and content of each on-site review should be determined according to the complexity of the domestic implementation and the materiality of the issues identified. Domestic banking regulators and supervisors are expected to be the main counterparts of the Assessment Team during the on-site assessment. Meetings with other relevant parties (including the finance ministry or treasury, other regulatory agencies, industry representatives, accounting representatives, rating agencies or analysts) may also take place to ensure that the Assessment Team collects a broad range of views and develops a sound understanding of local regulatory requirements and implementation issues. Meetings with the banking industry should take place if possible without the participation of representatives of the domestic authorities. The purpose of these industry meetings typically includes:
•
 discussing issues that could materially impact the quality and sustainability of implementation
(these will be driven by off-site work by the Assessment Team and should not be bank-specific);

•
 understanding the integrity of the implementation process in the jurisdiction and the readiness of the industry;

•
 giving the industry an opportunity to exchange views on the broader Basel framework and any unintended hurdles in implementation (including issues relating to a lack of clarity of Basel provisions); and

•
 informing the judgment of the Assessment Team on the materiality of issues where data are not available or where deviations are not quantifiable.

3.3
 Assessment methodology
 The general principles underlying the assessment methodology are set out below.
•
 The jurisdictional assessments focus on reviewing the content of domestic regulations. The assessment of compliance with the Basel rules will be based on:
–

12
 a comparison of domestic regulations with the international agreements to identify if all the required provisions of the Basel standards have been adopted (completeness of the regulations); and
 RCAP Jurisdictional Assessments Handbook

–
 notwithstanding the form of local requirements, whether there are any differences in substance between the domestic regulation and the Basel rules (consistency of the regulations).

•
 The assessment is not a word-for-word comparison. The objective is to ensure that substance of the specific Basel provision under review exists somewhere in the domestic regulation. That is, while a word-for-word comparison can be the starting point of the assessment – as differences in the choice of words may have a material effect – assessors should also take a step back and consider not only whether the assessed jurisdiction achieves the goals of the text but also the practical effect of deviations and the broader context of the assessment.

•
 The Assessment Team should focus on regulatory matters within the supervisory scope of the review. There are many prerequisites for effective supervision, as set out in the principles and preconditions in the Basel Committee’s Core principles for effective banking supervision. 9 The Assessment Team should not assess these factors nor make judgments outside the scope of the review (eg judgments on the underpinning of national legal systems) in reaching a view on compliance of domestic regulations with Basel standards.

•
 Consistent with the scope of the jurisdictional assessments, the Assessment Team is not expected to verify the actual implementation by banks if a regulation is prima facie compliant with the Basel provision.

•
 When a gap or difference is identified, a key driver for assessing compliance will be its materiality and impact. The component grades and overall grade are based on the aggregate impact of
(i) all deviations that are considered currently or potentially material; and (ii) all non-material deviations where the impact has been quantified. It is the impact of the deviations on the reported metrics at the component level rather than their number that determines the grade.

•
 The assessment will seek to clarify the rationale for any identified gaps and differences between the domestic provisions and the corresponding Basel rules, with a view to ensuring a clear understanding of the specificities and drivers of local implementation. This will help stakeholders view the assessment in its proper perspective. However, these elements are not taken into account when assessing compliance beyond the scope of national discretion already specified within Basel standards.

•
 If a single deviation affects several components (eg outflows and inflows in the RCAP-LCR or scope of application and definition of capital in the RCAP-Capital), the Assessment Team may judge that it affects the grading of both components. Alternatively, it may be reflected in the most affected component. In such situations, the team’s judgment should be explained clearly in the assessment report.

•
 Domestic measures that are stricter than the minimum Basel requirements are fully in line with the nature of the international agreements, which are intended to set minimum requirements, and will therefore be considered as compliant. However, they will not be considered to compensate for inconsistencies or gaps identified elsewhere.

•
 A distinction can be made between assessment findings, such as deviations and gaps, and observations. Observations highlight certain special features of the regulatory implementation of the Basel standards in the assessed jurisdiction. Observations are presented separately in the assessment report for contextual and informational purposes. They do not indicate subequivalence, but are considered compliant with the Basel standard and do not have a bearing on the assessment outcome.

9
 Available at www.bis.org/publ/bcbs230.htm. Assessments of the implementation of the core principles and preconditions are conducted primarily by the International Monetary Fund and the World Bank.
 RCAP Jurisdictional Assessments Handbook

13

3.4
 Bindingness of regulatory documents
 As noted above, the jurisdictional peer reviews assess to what degree domestic regulations in each member jurisdiction are aligned with the minimum requirements defined by the Basel Committee. Laws and regulations provide a framework to set and enforce prudential requirements for banks. While legal and regulatory structures differ across jurisdictions, the general expectation is that Basel minimum prudential standards are implemented through laws and regulations that are legally binding and can be enforced effectively. It is important that these laws and regulations are clearly distinguishable from instruments used to provide guidance to which banks might not have to strictly adhere. For the purpose of RCAP assessments, the regulations being assessed should encompass all domestic laws, regulations, rules, guidelines or any other documents implementing the Basel standards and deemed by law or in practice as binding on banks and the supervisory authorities. The list below defines criteria for the eligibility of instruments in RCAP assessments. The criteria aim to establish the legitimacy and “bindingness” of the instruments implementing the regulatory regime.
1.
 The instruments used are part of a well defined, clear and transparent hierarchy of a legal and regulatory framework.

2.
 They are public and easily accessible.

3.
 They are properly communicated and viewed as binding by banks and supervisors. 10

4.
 They would generally be expected to be legally upheld if challenged and are supported by precedent. 11

5.
 Consequences of failure to comply are properly understood and carry the same practical effect as for the primary law or regulation. 12

6.
 The regulatory provisions are expressed in clear language that complies with the Basel provisions in both substance and spirit.

7.
 The substance of the instrument is expected to remain in force for the foreseeable future.
 Key elements of Basel standards should be implemented through laws and regulations. Only interpretative issues and clarifications should be conveyed via FAQs, supervisory guidance or other ad hoc instruments. Assessments will be based, whenever possible, on the final domestic regulations implementing the Basel standards. If a jurisdiction is still implementing parts or all of the standard during the assessment phase, the Assessment Team can assess draft regulations being considered as part of the domestic rule-making process. However, the regulations must be in place by the cut-off date to be eligible for the RCAP assessment. Where a jurisdiction makes rectifications during an assessment to align its standards, the regulations must also be enacted by the cut-off date. Generally, such rectifications should also apply to financial institutions no later than the cut-off date. However, where the authorities in the assessed jurisdiction consider it necessary to allow a short transitional period for banks to implement the

10
 For the purpose of RCAP assessments, the Assessment Team should consider whether the regulated community believes that failure to comply would risk the regulator’s general displeasure and/or imply a specific sanction for non-compliance.

11
 In certain jurisdictions the principles of administrative law and their application to the circumstances of adoption of the particular instrument will determine whether that instrument would be upheld by a court or not (eg has the regulatory body exercised its powers properly? Has it taken into account all relevant circumstances and disregarded irrelevant circumstances?).

12
 In certain situations, it may not necessarily undermine the binding nature of the instrument if the regulator nevertheless takes action that is inconsistent with it, for example in the case of a supervisory discretion that is allowed by the Basel framework. In such cases, the Assessment Team must judge whether the regulator has applied the instrument in the spirit of the Basel framework.

14
 RCAP Jurisdictional Assessments Handbook

amendments, this will not prevent the revised regulations being taken into account for the RCAP assessment. Such delays should in principle not exceed six months. For RCAP purposes, the assessed jurisdiction should provide information, with its self-assessment, on the hierarchy of legal and regulatory instruments and the ways in which they are used. In arriving at its assessment, assessors will seek additional feedback from relevant third parties to evaluate the status of instruments other than laws and regulations. Assessment Teams can rely on the assessments of bindingness made in previous RCAP assessments where there has been no change to a jurisdiction’s legal framework and where the same instruments are used.

3.5
 Materiality assessment
 The basis of materiality assessment of identified deviations is the impact on the reported prudential metrics of the RCAP sample banks (see Section 2.4). Materiality can be interpreted along two dimensions:
(i) confidence in banks’ prudential ratios (financial stability dimension); and (ii) an adequate calculation of these ratios by internationally active banks (level-playing-field dimension). In addition, a view on materiality can be formed that is time-independent to ensure that the assessment is robust over time. This implies that teams should consider that the materiality of gaps can change over time, driven by factors such as refinements to the regulatory regime, the economic cycle, financial trends, and shifts in banking practices such as from standardised to advanced regulatory approaches. The Assessment Team should classify any identified gaps as quantifiable or non-quantifiable deviations. Quantifiable deviations are those whose materiality can be estimated in quantitative terms. The impact of non-quantifiable deviations is estimated using expert judgment. Assessment Teams are expected to be as consistent as possible in assessing materiality across both quantifiable and nonquantifiable deviations. The assessment will consider both the current impact and consequences and the potential impact in the future. In areas where quantitative evidence is lacking, or is of doubtful relevance or quality, or where the Assessment Team believes it is appropriate to take local circumstances into account, or when gaps are potentially material even when they are not currently material, judgment will be crucial. In these cases, the Assessment Team is expected to adopt a conservative view. This principle applies to all materiality assessments, whether quantifiable or not, and whether considering current or potential materiality.

3.5.1
 Quantifiable deviations
 Where a deviation is quantifiable, Assessment Teams should calculate the effect of the deviation on the reported prudential metrics relevant for the standard being assessed. For example, an RCAP-Capital assessment will estimate the effect on reported capital ratios and risk-weighted assets (RWAs). In general, for quantifiable deviations, bank-specific data will be requested to support the analysis of materiality. The data should reflect the full implementation of the Basel standards and should not take into account phase-in arrangements. Where local regulations are assessed to be in line with the Basel rules, there is no requirement to provide data for materiality testing. Likewise, where the domestic regulations impose requirements on banks over and above the requirements in the Basel text, the provision of supporting data is optional. In some cases, data limitations can hamper the materiality assessment of quantifiable gaps. Where a direct estimate of the impact is not possible, the Assessment Team should make every attempt to assess materiality based on proxies such as the level of exposure to the affected asset class, the number of banks engaged in specific business activities, data from public sources, impact studies or other similar information made available by the assessed jurisdiction. Teams are encouraged to use their collective expertise to form a best-efforts estimate of the impact on the prudential ratios of banks. This would allow the RCAP to put together a view on quantifiable gaps that is as consistent as possible.
 RCAP Jurisdictional Assessments Handbook

15

3.5.2
 Non-quantifiable deviations
 Non-quantifiable deviations can be either deviations that are potentially quantifiable for which there is insufficient data to make a quantitative estimate or deviations that are inherently non-quantifiable. Some aspects of the Basel framework are not quantifiable by nature. For instance, gaps in Pillar 1 involving areas relating to governance around the use of internal models, or gaps in Pillar 2 or Pillar 3 would fall into this category. The materiality of such gaps should be assessed based on the degree of uncertainty these gaps are likely to cause, at present or in the future, regarding the accuracy of the capital measurement process and/or the quality of risk management when that is relevant. For instance, in the case of Pillar 2, the materiality of risks not captured under domestic regulations should be judged within the context of their importance for financial stability and the level playing field. An assessment of non-quantifiable deviations and their impact is based largely on the subjective judgment of Assessment Teams. The following considerations should be kept in mind when assessing such deviations, as well as the grade definitions given in Section 3.6.1.
•
 Scope of the deviation, eg in terms of portion of capital instruments affected (relative to total capital), extent of exposures affected, number of parameters affected or business lines involved.

•
 Number and type of banks impacted by the deviation.

•
 Likely impact on the quality of risk management or the capital (or liquidity) measurement process.

•
 Extent of deviation in a provision. If the provision is missing entirely, its impact is likely to be higher as compared with the situation when only part of the provision is missing.

•
 Extent of impact on market discipline.
 In evaluating the impact of the non-quantifiable deviations and aggregating that with the quantitative impact of other deviations, Assessment Teams should apply expert judgment in a consistent manner.

3.5.3
 Guidance on potential materiality and impact
 An assessment of the potential materiality of a deviation will often require more judgment than reliance on data alone, especially concerning the scenarios under which and the likelihood of a deviation becoming material. This section provides guidance on how to approach such an assessment on a sound and a consistent basis. A good starting point for approaching a deviation that may not be material today but may be in the future is to consider the following questions and examine whether there is a reasonable chance that the deviation will assume significance within the next three years:
1.
 Under what realistic scenarios would the deviation become material? 13

2.
 What is the likelihood of the scenarios occurring within the assessment horizon, notably with regard to economic or financial system trends?

3.
 What specific structural factors could make an assessment finding less likely to become material? Are there any reasons to believe that these structural factors could change?

4.
 Which banks in the RCAP sample are likely to be most affected given the nature of the deviation? If the deviation only affects banks specialised in certain businesses, do they pose systemic risks or raise international competitive equity issues?

13

16
 A scenario is a possible future event or environment, either at a point in time or over a period of time. A projection of the effects of a scenario over the time period studied can address either a particular firm or an entire industry or national economy.
 RCAP Jurisdictional Assessments Handbook

5.
 How large could the potential impact of the deviation be? For example, for the RCAP-Capital, this would be assessed in terms of the overall capital ratio and in terms of the RWA or capital calculated for that component of the Basel framework. When gauging potential materiality, the following should be considered:

•
 Quantification: where possible, the team should quantify the impact under different realistic scenarios.

•
 Data sources: if available, teams should inform their assessment by well regarded third-party analyses. For example migration matrices from rating agencies or economic forecasts by the IMF or OECD may be helpful in estimating the probability of a scenario.

•
 Accountability: all assumptions, inputs and calculations used in the analysis need to be documented in appropriate detail. Documentation should be sufficient to allow the Review Team or PRB to review the materiality analysis independently.

•
 Expert judgment: in the light of the judgment that must be exercised in estimating the probabilities of scenarios occurring, the Assessment Team should also overlay expert judgment on their assessment of potential materiality.

•
 No changes to regulation: the Assessment Team should not consider the possibility of changes to regulation after the cut-off date, even if they are planned at the time of the assessment. Similarly, the Assessment Team should not assess the possibility of future changes to the jurisdiction’s legal framework. However, the effect of existing regulations or legislation coming into force may be a relevant factor (eg a jurisdiction has enacted laws expanding or limiting the scope of activities permitted for banks before the cut-off date, but those laws have not yet come into effect, or are still in a transitional period). If there are draft laws or regulations relaxing the provisions being assessed, they should not be included in the scope of the assessment but may be considered as an item for follow-up.
 Deviations that are not potentially material should still be reported in the assessment report. These deviations are considered not material. In doing so, the Assessment Team must explain why a deviation is not considered potentially material.

3.6
 Assigning grades

3.6.1
 Compliance scale
 The outcome of the assessment process takes the form of an overall assessment of the compliance of the jurisdiction’s regulation with the defined Basel standards and assessments of the compliance of the jurisdiction’s regulation for each of the key components of the standard being assessed. All assessments will use a four-grade scale, both at the level of components and at the overall level. These grades are defined in Table 2.
 RCAP Jurisdictional Assessments Handbook

17

Assessment grades Grade
 Table 2 Definition
 Regulation is compliant with Basel standards
 A regulation will be considered compliant if all minimum provisions of the international framework have been satisfied and if no material differences have been identified which would give rise to prudential concerns or provide a competitive advantage to internationally active banks.
 Regulation is largely compliant with Basel standards
 A regulation will be considered largely compliant with Basel standards if only minor provisions of the international framework have not been satisfied and if only differences that have a limited impact on financial stability or the international level playing field have been identified.
 Regulation is materially noncompliant with Basel standards
 A regulation will be considered materially non-compliant with Basel standards if key provisions of the international framework have not been satisfied or if differences that could materially impact financial stability or the international level playing field have been identified.
 Regulation is non-compliant with Basel standards
 A regulation will be considered non-compliant if Basel standards have not been adopted or if differences that could severely impact financial stability or the international level playing field have been identified.
 Note: This four-grade scale is consistent with the approach used for assessing countries’ compliance with the Basel Committee’s Core principles for effective banking supervision. The actual definition of the four grades has, however, been adjusted to take into account the different nature of the two exercises. In addition, as noted in paragraph 8 of the Basel III standards published in December 2017, a jurisdiction that does not implement some or all of the internally modelled approaches but instead only the standardised approaches may still be compliant with the Basel framework. In such cases, components that are not relevant to an individual jurisdiction (eg those relating to advanced approaches that have not been implemented) will be assessed as non-applicable.
 To avoid any misunderstanding about the level of compliance, especially between the materially non-compliant and non-compliant grades, the press release that accompanies the publication of the assessment reports will clarify the positioning of the assessed jurisdiction’s overall grade, eg with the following wording: “The overall grade for [name jurisdiction] was therefore assessed as [compliant, which is the highest overall grade; largely compliant, which is one notch below the highest overall grade; materially non-compliant, which is one notch above the lowest overall grade; and non-compliant, which is the lowest overall grade].” Also, the presentation of the overall grade will be supplemented by clear and concise text spelling out the weaknesses and strengths in the jurisdiction’s compliance or non-compliance that have contributed to the overall grade.

3.6.2
 Grading methodology
 Grade assignments should be based largely on the impact of the identified gaps, ie the impact of the identified deviations between the formal published texts of local rules and regulations, and the Basel standards. Section 3.5 discusses the RCAP methodology for assessing materiality. Assessment Teams must not use areas of super-equivalence to offset the impact of deviations from the Basel standards. Once the materiality of the individual deviations has been determined, the Assessment Team should determine the assessment grades for each component. The following three-step approach should guide this process:
1.
 For each component, the cumulative impact of the quantifiable gaps is calculated. This produces a preliminary component grade.

2.
 For each component, the cumulative impact of non-quantifiable gaps is evaluated. The preliminary grade is then adjusted to reflect these additional deviations. As the focus is on the cumulative materiality of the deviations, the Assessment Team should not average out between

18
 RCAP Jurisdictional Assessments Handbook

the quantifiable and non-quantifiable deviations, ie the grade derived in step 1 should be kept the same or lowered, but not improved.
3.
 A final judgmental check is applied to ensure that the resulting component grade is consistent with the description of the grade. Any new consideration affecting this judgment should be documented and explained in the assessment report.
 Having determined the component grade, the Assessment Team should determine the overall grade following the four steps below. In aggregating results for different gaps within and across key components, judgment will be critical in assessing their potential interactions and relative importance.
1.
 The cumulative impact of all quantifiable gaps is calculated. This produces a preliminary grade.

2.
 The cumulative materiality of all non-quantifiable gaps is assessed. Again, the grade derived under step 1 can only be kept the same or lowered, but not improved.

3.
 The constraint is applied that the overall grading cannot be higher than one notch compared with the worst component grade. 14

4.
 A final judgmental check is applied to assess whether the resulting overall grading is consistent with the description of the grade. Any new consideration that plays a role for the assignment of the final grade should be appropriately documented and explained in the assessment report.
 In step 2 of each of the processes above, the impact of quantifiable and non-quantifiable deviations will be additive at the level of both the component and the framework when determining assessment grades. The same grading methodology applies when reviewing grades as part of follow-up assessments
(see Section 5.2.1). The guidance for assessment materiality and determining component grades and the overall grade set out in this section recognises that all RCAP assessments are ultimately based on the collective judgment of the Assessment Team. It is not meant to force RCAP assessments into becoming mechanical exercises. Indeed, assessors are expected to use regulatory and supervisory common sense as they apply it. They should feel free to adapt it as needed, provided they describe and explain their adjustments in the RCAP report. Beyond this guidance, the assessment process has built-in checks and balances to ensure that materiality determination and grading assignment are fair and consistent. These include the Scoping Note, the four-eyes review within each Assessment Team, ongoing involvement of the Committee’s Head of Basel III Implementation across all RCAPs and the review process described in Section 5.

3.7
 Interpretative issues
 Jurisdictional assessments inform the Basel Committee about implementation challenges and interpretative issues that member jurisdictions and Assessment Teams come across when assessing the consistency of the domestic regulatory frameworks. Specifically, the assessments identify areas where further clarification is needed to ensure consistent implementation. Overall, the aim is to clarify interpretative issues as promptly and accurately as possible. Hence, whenever possible, interpretative issues should be clarified during the assessment. Where an interpretative issue cannot be resolved during an assessment, the issue may be scoped out from the assessment and

14
 For example, a jurisdiction that has one component assessed as materially non-compliant cannot receive an overall grading higher than largely compliant.
 RCAP Jurisdictional Assessments Handbook

19

listed for further review by the Committee. The Committee can decide to direct the matter to one or more of its working groups after discussing the assessment report (see also Section 5.2.3).

3.8
 Amendments or extensions of the RCAP methodology
 In the course of a consistency assessment, methodological questions may arise. In such a case, the Secretariat and the Team Leader, after discussion with the Committee’s Head of Basel III implementation, will propose a course of action to the PRB. The PRB then determines the approach for the purposes of the ongoing assessment. If there is sufficient time and the issue is not unduly sensitive, feedback from SIG should be requested before submitting the draft assessment report to the Basel Committee. Otherwise, the PRB can decide to raise the matter directly with the Basel Committee. Before a new process or a new criterion can be incorporated in the Handbook and become a precedent for subsequent RCAPs, it must be reviewed and approved by the SIG. If sufficiently important, or if different from the one-off decision taken by the Committee, these changes should then be forwarded to and approved by the Basel Committee. Once agreed by the SIG and/or the Committee as appropriate, the methodology will be updated and included in the Handbook.
 Flow chart summarising methodology changes during an assessment
 The Assessment Team identifies a methodological issue and discusses with Secretariat. If the issue cannot be resolved, then it is escalated to the PRB.

3.9
 The PRB decides if there is time for an SIG review and if the issue can be widely discussed.
 No
 Yes
 The PRB makes a one-off recommendation to the Assessment Team.
 The issue goes to the SIG for a oneoff recommendation to the Assessment Team.
 Chart 2
 The SIG provides the Committee with feedback on the recommendation before the Committee discusses for approval a revised version of the Handbook.
 Drafting the RCAP report
 Standard parts of an RCAP report can be drafted during the off-site phase. These include the background information relating to regulations and banking system of the assessed jurisdiction included both in the report and annexes. The Secretariat will prepare the first draft of these sections. Some parts of the report (eg data, annexes included for information only) are completed by the authorities of the assessed jurisdiction. The Secretariat will suggest templates to the assessed jurisdiction during the early stages of the assessment. These will be completed by the jurisdiction ahead of the onsite assessment, where possible (though some quantitative information may have to be updated prior to publication). Assessment Teams should aim to send a list of the preliminary findings to the assessed jurisdiction prior to the on-site assessment. Where possible, this should be in the report format, so that

20
 RCAP Jurisdictional Assessments Handbook

the report can be easily updated during the on-site assessment and presented to the authorities of the assessed jurisdiction at the end of the visit. Jurisdictions being assessed will be given an opportunity to comment on the draft report before the review phase. As part of this process, the assessed jurisdiction will have the opportunity to present its views on the findings of the assessment and have them reflected in a separate section of the report. Comments provided by assessed jurisdictions will be carefully considered by the Assessment Team, who should be prepared to explain how they have dealt with the major comments. However, the assessment report remains an expert report of the Assessment Team and should not become a matter of negotiation between the Assessment Team and the authorities. Teams may list contextual observations regarding the regulatory implementation of the Basel standards separately in the assessment report. Observations do not indicate sub-equivalence, but are considered compliant with the Basel standard and do not have a bearing on the assessment outcome. The annexes to an RCAP report include the information listed below. Annexes specific to the assessment of individual standards are listed in Sections 6–10.
•
 Assessment and Review Team members

•
 List of Basel standards used in the assessment

•
 Local regulations implementing the relevant Basel standards

•
 Summary of the materiality assessment

•
 List of rectifications made during the assessment (if applicable)

•
 Areas for further guidance from the Basel Committee (if applicable)

•
 List of issues for follow-up RCAP assessments (if applicable)

•
 Areas where a jurisdiction’s rules are stricter than the Basel standards (if applicable)
 As noted in Section 5.2.1, any follow-up assessments should generally be described in a separate report, to make it easier for stakeholders to track changes to the assessments of individual standards. The Basel Committee has the final responsibility for approving jurisdictional assessment reports
(see Section 4.2).
 RCAP Jurisdictional Assessments Handbook

21

4
 Review phase
 Flow chart of review process
 Chart 3
 SIG Assessment Team Four-eyes review of domestic regulations
 Review Team
 Plenary review of draft assessment report
(excluding grades)
 Review draft assessment report PRB Review draft assessment report (including grades) and feedback from the SIG. Approve submission to Committee

4.1
 Basel Committee Plenary review of assessment report for approval and publication
 Review Team and SIG
 The Review Team will review the draft report before the draft report goes to the SIG and PRB for review and approval. Comments raised by the Review Team will be shared with the SIG when the SIG is informed by the Team Leader about the material findings or policy issues arising from the RCAP assessment. The Review Team may also be asked by the PRB to provide an opinion specifically on how the focus on substance has been met and is reflected in the draft RCAP report, eg by considering the proportionality between the identified deviations and the grades and whether the assessment is balanced and sufficiently supported by analysis and consistent with previous assessments. Should there be situations where the Team Leader and the Review Team hold different views, these will be reported to the SIG. The Head of Basel III Implementation may also refer the matter to the PRB for review and resolution. The SIG reviews the draft assessment reports (without grades) and provides feedback to the Team Leader and Assessment Team. The Secretariat will report to the PRB on the discussions at the SIG before the Peer Review Board approves the report for submission to the Committee. The Review Team and SIG can instruct their technical experts to discuss some parts of the draft RCAP assessment reports, provided that these experts adhere to the confidentiality agreements of the Committee. Review Team members can also request access to underlying assessment information, subject to the appropriate confidentiality arrangements.

4.2
 Approval of the report: Peer Review Board and Basel Committee
 The PRB reviews the report and approves it to be sent to the Committee. The ownership of the assessment report is transferred from the Assessment Team to the Committee once the report has been cleared by the PRB and circulated to the Committee for discussion and approval.

22
 RCAP Jurisdictional Assessments Handbook

The Basel Committee has the final responsibility for approving jurisdictional assessment reports. Assessments are approved by consensus. If full consensus cannot be reached during the Committee meeting to which the report is presented, minority views will be footnoted in the report. Jurisdictions being assessed will be given an opportunity to comment on the draft report during the Committee meeting but will not take part in the decision-making.
 RCAP Jurisdictional Assessments Handbook

23

5
 Publication and follow-up of RCAP assessments

5.1
 Publication
 After formal approval by the Committee, the report, including the response from the assessed jurisdiction, will be published on the Committee’s website. The Committee member from the assessed jurisdiction will also be invited to publish the report on its website.

5.2
 Follow-up
 The RCAP follow-up processes allow the Committee to keep abreast of the continuing efforts by its members to implement Basel standards. The aim is to provide some continuity between assessments as well as a foundation for more tailored and streamlined implementation follow-up. Further, this will improve the quality of reporting to the G20, the FSB and other external stakeholders on progress with implementation of the Basel framework. Above all, the process is intended to help member jurisdictions to systematise and communicate their own monitoring efforts at the national level. The three types of RCAP follow-up are (i) items listed by the Assessment Team in RCAP reports as issues that should be reviewed by future Assessment Teams in subsequent RCAP assessments; (ii) annual reporting by jurisdictions on steps taken or planned to address RCAP findings; and (iii) interpretative issues, which should be reviewed by the Committee or its working groups.

5.2.1
 Items listed for follow-up in RCAP reports
 Issues identified by Assessment Teams for follow-up in future RCAP assessments are listed in the RCAP reports. These items should generally be limited to findings classified as having a material or a potentially material impact. Follow-up assessments then focus on re-assessing the materiality of these findings and assessing any rectifications or amendments undertaken by the jurisdiction following the publication of the assessment report. An item listed for follow-up that does not relate directly to a material or potentially material finding, including an item listed as an observation instead of a deviation, should be highlighted during the review process. Generally, items listed for follow-up are included in the scope of subsequent RCAP assessments
(see also Section 2.4). 15 These should be discussed by the Team Leader and the assessed jurisdiction at an early stage, to ensure that Assessment Teams have the appropriate expertise. Only in exceptional circumstances, where the items listed for follow-up have no connection to the scope of the current assessment and where it is extremely challenging to find assessors with the appropriate mix of expertise, should items for follow-up be excluded from the scope of subsequent assessments. The final decision on the scope of the assessment rests with the Team Leader, who should consult the Committee’s Head of Basel III Implementation and, if needed, the PRB. Where items for follow-up are included in the scope of subsequent assessments, they should generally involve a re-assessment of the relevant component and its grade. Where new regulations have been issued, the Assessment Team should review these against the Basel standards. Where regulations have not changed, Assessment Teams reviewing items for follow-up need not repeat the line-by-line

15

24
 As an exception to this general principle, the SIG and the Committee agreed that items listed for follow-up in RCAP-Capital assessments need not be included in the scope of the RCAP-NSFR and large exposures assessments (although this may still be done at the discretion of the assessed jurisdiction).
 RCAP Jurisdictional Assessments Handbook

assessment of the previous team, but may focus instead on the findings previously identified. In particular, the Assessment Team should consider whether revisions to the materiality assessment are warranted, along with the component grade. 16 Assessment Teams should also consider whether their review of the items for follow-up presents any reason to change the overall grade. In some cases, there may be a clear justification for a change. For example, a material finding listed for follow-up may have been rectified, leading to the improvement of a low component grade which had previously acted as a constraint on the overall grade. On the other hand, a potentially material finding may not have been rectified and instead have become material, leading to a downgrade of the component grade to one which now acts as a constraint on the overall grade. However, in many cases, the component being reviewed may not dominate the overall grade and its impact on the overall grade may be difficult to assess in isolation. In such cases, Assessment Teams may note that they did not see a clear reason for changing the overall grade. The Assessment Team’s review of items listed for follow-up should generally be described in a separate report, to make it easier for stakeholders to track changes to the assessments of individual standards. Assessed jurisdictions may also request follow-up assessments on any components reviewed in previous assessments, even if they have not been listed as an item for follow-up. A jurisdiction may consider this to be beneficial where it has implemented several regulatory reforms on a given topic. This should be discussed with the Team Leader at the scoping stage (see Section 2.4).

5.2.2
 Reporting on follow-up by assessed jurisdictions
 Based on a monitoring template completed by jurisdictions whose assessments were completed and published at least 12 months previously, an annual report is presented to the Committee on the followup actions taken by those jurisdictions. This means that RCAPs published during 2013 are covered in the
2015 follow-up report, 2014 RCAPs are covered in the 2016 follow-up report and so on. This report explains how the deviations from the Basel requirements identified in the assessment report were addressed or what proposals have been made to address them. The report will include new or amended Basel-based requirements or regulatory changes that have been enacted by the assessed jurisdiction. The report is based on submissions from Committee members. Following approval by the Committee, the individual submissions are published on the Basel Committee website (alongside the original RCAP assessment reports), with a cover note summarising the actions taken by all jurisdictions subject to reporting in that year. 17

5.2.3
 Interpretative issues
 Following the Committee discussion on the RCAP report, any interpretative issues highlighted are typically submitted to one of the Committee’s working groups for follow-up. Whenever required, the standard policymaking process is followed: the PDG (for example) decides to assign the interpretative issue to one of its working groups for clarification (eg through an FAQ or a proposal for amendment of the Basel standard). Subsequently, the FAQ or policy amendment is discussed by the PDG and submitted to the Basel Committee for approval. Depending on the nature of the issue, the Committee can approve for publication or require a public consultation on revisions to a standard before giving final approval.

16
 Where a jurisdiction has not issued new regulations and does not intend to address the finding, follow-up work will normally only involve a review of the materiality and its effect on the component grade.

17
 The reports are available at www.bis.org/bcbs/implementation/rcap_jurisdictional.htm.
 RCAP Jurisdictional Assessments Handbook

25

The outcome of this process will not result in retrospective revisions to grades of RCAP assessments already published where the issue was scoped out from the assessment and listed for further review by the Committee.
 Flow chart of interpretative issues
 The report identifies an interpretative issue. The Committee discusses whether the issue should be clarified via the PDG or SIG.

26
 The PDG or SIG decides whether to assign the issue to one of the working groups for clarification or follow-up (eg FAQ or amendment of Basel standard).
 Chart 4
 PDG approves the FAQ or amendment for submission to the Committee.
 Basel Committee approves FAQ or amendment for publication or public consultation.
 RCAP Jurisdictional Assessments Handbook

6.
 RCAP-Capital: assessments of Basel risk-based capital standards

6.1
 Scope
 The first RCAP assessments of risk-based capital regulations cover the capital standards in Basel II, 2.5 and III. 18 The following Basel standards (including any applicable annexes) are in the scope of the assessment:
•
 Basel II: International Convergence of Capital Measurement and Capital Standards: A Revised Framework – Comprehensive Version (June 2006)

•
 Enhancements to the Basel Framework (July 2009)

•
 Guidelines for computing capital for incremental risk in the trading book (July 2009)

•
 Final elements of the reforms to raise the quality of regulatory capital issued by the Basel Committee
(January 2011)

•
 Revisions to the Basel II market risk framework – updated as of 31 December 2010 (February 2011)

•
 Basel III: A global regulatory framework for more resilient banks and banking systems – revised version (rev June 2011)

•
 Pillar 3 Disclosure Requirements for Remuneration (July 2011)

•
 Treatment of trade finance under the Basel capital framework (October 2011)

•
 Interpretive issues with respect to the revisions to the market risk framework (November 2011)

•
 Composition of capital disclosure requirements – Rules text (June 2012)

•
 Capital requirements for bank exposures to central counterparties (July 2012)

•
 Regulatory treatment of valuation adjustments to derivative liabilities: final rule issued by the Basel Committee (July 2012)

•
 FAQs published by the Committee on the standards above, including those that would solve any interpretative issue arising during the assessment
 The assessment covers 14 components, as listed in Table 3. Assessed jurisdictions receive a grade for each of these components as well as an overall grade.

18
 The first RCAP-Capital assessments were conducted between 2012 and 2016. Subsequent assessments will include reforms to the risk-based capital framework agreed since 2012, including (but not limited to) the finalised Basel III post-crisis reforms published in December 2017.
 RCAP Jurisdictional Assessments Handbook

27

Components of risk-based capital framework subject to RCAP assessment
 Table 3
 General provisions and definition of capital Scope of application Transitional arrangements Definition of capital Pillar 1: Minimum capital requirements Credit risk: Standardised Approach Credit risk: Internal Ratings-Based approach Credit risk: securitisation framework Counterparty credit risk Market risk: standardised measurement method Market risk: internal models approach Operational risk: Basic Indicator Approach and Standardised Approach Operational risk: Advanced Measurement Approaches Capital buffers (conservation and countercyclical) Pillar 2: Supervisory Review Process Legal and regulatory framework for the Supervisory Review Process and for taking supervisory actions Pillar 3: Market Discipline Disclosure requirements

6.2
 Design
 Given the size of the risk-based capital framework, these RCAP assessments are designed as jurisdictional assessments ie peer reviews undertaken by a team of technical experts reviewing the implementation in a single jurisdiction. Assessment Teams typically comprise around five experts, in addition to the Team Leader. These assessments cover all Committee member jurisdictions with initial priority given to countries where global systemically important banks (G-SIBs) are domiciled.

6.3
 Methodological considerations specific to RCAP-Capital
 RCAP-Capital assessments should be conducted following the general assessment methodology set out in Section 3.

6.4
 Report
 RCAP-Capital reports include the following annexes in addition to those listed in Section 3.9.
•
 A description of the jurisdiction’s implementation of the Pillar 2 supervisory review process

•
 Key financial and capital adequacy information on the banking system in the jurisdiction being assessed

•
 List of approaches not allowed by the assessed jurisdiction’s regulatory framework

28
 RCAP Jurisdictional Assessments Handbook

7.
 RCAP-LCR

7.1
 Scope
 The RCAP assessments of the Basel LCR examine implementation of the LCR minimum and calculation and the related LCR disclosure standards. The following Basel standards (including any applicable annexes) are in the scope of the assessment:
•
 Basel III: The Liquidity Coverage Ratio and liquidity risk monitoring tools (January 2013), excluding the section on the liquidity risk monitoring tools

•
 Liquidity Coverage Ratio disclosure standards (January 2014)

•
 The Liquidity Coverage Ratio and restricted-use committed liquidity facilities (January 2014)

•
 FAQs published by the Committee on the standards above, including those that would solve any interpretative issue arising during the assessment
 The LCR standard permits countries with an insufficient supply of high-quality liquid assets
(HQLA) to implement an alternative liquidity approach (ALA). Paragraph 55 and Annex 2 stipulate eligibility criteria for ALA. The eligibility for an ALA is determined by an independent peer review process, overseen by the Working Group on Liquidity (WGL), the PDG and the Committee. It is not in the scope of the RCAPLCR assessments. The RCAP-LCR assessments do assess the implementation of any ALA and the standards governing banks’ use of such approaches. The assessment covers four components, as listed in Table 4. Assessed jurisdictions receive a grade for each of these components as well as an overall grade.
 Graded components of the Basel LCR framework
 Table 4
 High-quality liquid assets (numerator) Outflows (denominator) Inflows (denominator) LCR disclosure requirements
 While outside the scope of the formal assessment and grades, the RCAP-LCR assessments collect information on national LCR implementation practices. This is presented in several annexes of the report
(see Section 7.4). This should help the WGL, the PDG, and the Committee identify implementation issues where clarifications and (additional) FAQs could improve the quality and consistency of implementation. It should also inform the preliminary design of any peer comparison of consistency across the membership that the Committee may decide to do, akin to the studies on RWA variation for the capital standards. The following Basel documents are relevant for this aspect of the RCAP-LCR, being reviewed for information purposes only:
•
 Basel III: The Liquidity Coverage Ratio and liquidity risk monitoring tools (January 2013), the section on the liquidity risk monitoring tools only

•
 Monitoring tools for intraday liquidity management (April 2013)

•
 Principles for sound liquidity risk management and supervision (September 2008)

7.2
 Design
 As in the case of the assessment of the risk-based capital standards, given the specialised nature of the subject matter and to ensure sufficient rigour, the RCAP-LCR assessments are designed as jurisdictional RCAP Jurisdictional Assessments Handbook

29

assessments ie peer reviews undertaken by technical experts reviewing the implementation in a single jurisdiction. Teams will typically comprise two assessors, in addition to the Team Leader. These assessments cover all Committee member jurisdictions. Where possible, the assessment is conducted jointly with the RCAP-Capital assessment.

7.3
 Methodological considerations specific to the RCAP-LCR
 In general, RCAP-LCR assessments should be conducted following the assessment methodology set out in Section 3. This includes the approach to classifying deviations, consideration of both quantitative impact and qualitative factors, the grades assigned and the grading approach. This section describes specific factors relevant to an assessment of LCR implementation, in order to achieve as much consistency as possible across jurisdictions, to support rigorous analysis by the Assessment Team and to make efficient use of resources. The LCR standard is a standardised approach based on a predefined weighting scheme. This has two major implications for the assessment of its implementation. First, it makes the assessment of regulatory consistency more tangible as compared with the assessment of internal model-type approaches. Second, any deviation from the Basel requirements will affect the mapping of assets and liabilities into the LCR buckets ie the HQLA haircuts, inflow and outflow factors or the assignment of assets and liabilities to the regulatory categories. In addition to its interaction with the supervisory authority of the assessed jurisdiction, the Assessment Team may also establish contact with the central bank and the deposit insurance agency on a need-to-know basis. This could be in the context of the data collection or in terms of the central bank’s role as lender of last resort and provider of other liquidity facilities (eg restricted-use committed liquidity facilities) or the assessment of the deposit insurance scheme’s effectiveness. Meetings with the banking sector and other representatives from the private sector (such as audit firms, consultants and experts for a specific jurisdiction) will provide assessors with a more comprehensive view on implementation, and to verify findings, but will not be typically be used for the quantitative assessment.

7.3.1
 Quantitative assessment
 Unlike in the case of the RCAP-Capital, the dynamic nature of liquidity risks warrants data collection at different points in time. Because the LCR can fluctuate over time, quantitative materiality data for the assessments are collected at three points in time. In line with the underlying RCAP principles of a conservative approach and facilitation of a level playing field, the materiality analysis focuses on the most conservative estimates, ie the highest impact. The points in time for which data are collected are agreed between the TL and the assessed jurisdiction and specified in the Scoping Note. 19 The data collection includes specific requests to assess the materiality of potential deviations. It may also include data collected through the Committee’s regular Basel III monitoring exercise 20 or other information collected by the WGL. As part of the response to the RCAP-LCR questionnaire, the Assessment Team should be given access to the national LCR reporting template.

7.3.2
 Qualitative assessment
 There is a significant qualitative element underlying the computation of the LCR, which requires implicit or explicit regulatory and supervisory treatment (often by taking into account the situation in the respective jurisdiction and market-specific circumstances). A key challenge of the LCR assessment is thus to ensure that, within the scope of differences in regulatory and supervisory treatments provided for by

19
 For example, the data collection could include quarterly or monthly data, depending on availability.

20
 See www.bis.org/bcbs/qis/index.htm.

30
 RCAP Jurisdictional Assessments Handbook

the LCR standard, bank assets and liabilities are mapped consistently to the appropriate LCR categories on both sides of the balance sheet (ie that LCR computations are consistent across jurisdictions). Given the symmetry between the “outflows” and “inflows” components, deviations may be identified that affect both. In such cases, as described in Section 3.3, the team may judge that a single deviation affects the grading of both components. The assessment report should explain clearly how the team has made its judgment in such a situation. The subsequent review process will review the quality and consistency of assessment.

7.4
 Report
 RCAP-LCR reports include the following annexes in addition to those listed in Section 3.9.
•
 Key liquidity indicators of the assessed jurisdiction’s financial system and the sample banks

•
 A description of the jurisdiction’s implementation of the Basel liquidity monitoring tools

•
 A description of the jurisdiction’s adoption of the Principles for sound liquidity risk management and supervision

•
 Implementation of LCR elements subject to prudential judgment (Table 5) or national discretion
(Table 6)
 In addition, where a jurisdiction implements an ALA, the report should also contain a brief description (although not an assessment) of the approach.
 Elements of the LCR requiring judgment (non-exhaustive list) Basel paragraph
 Description

24f
 Treatment of the concept of “large, deep and active markets”

50
 Treatment of the concept of “reliable source of liquidity”

52
 Treatment of the concept of “relevant period of significant liquidity stress”

74–84
83, 86
 Division of retail deposits into “stable” and “less stable” categories Treatment of the possibility of early withdrawal of funding with maturity above 30 days, for retail deposits (paragraph 83) and wholesale funding (paragraph 86)

90–91
 Definition of small business customers

94–103
 Deposits subject to “operational” relationships

131f
 Table 5
 Definition of other financial institutions and other legal entities
 RCAP Jurisdictional Assessments Handbook

31

Elements left to national discretion (non-exhaustive list) Basel paragraph
 Table 6
 Description

5
 Parameters with elements of national discretion should be transparent and clearly outlined in the regulations of each jurisdiction to provide clarity both within the jurisdiction and internationally

8
 Use of phase-in options Supervisory guidance on HQLA usability

11
 Implementation schedule for countries receiving financial support for macroeconomic and structural reform purposes

50b
 Eligibility of central bank reserves

50c
 Marketable securities assigned a 0% risk-weight under the Basel II Standardised Approach for credit risk

53–54
54a
 Provision relating to the use of restricted contractual committed liquidity facilities

55f
 Treatment for jurisdictions with insufficient HQLA (subject to separate peer review process)

68
 Treatment of sharia-compliant banks

78
 Treatment of deposit insurance

79f
 Categories and run-off rates for less stable deposits

123
 Market valuation changes on derivative transactions

134–140
 Run-off rates for other contingent funding liabilities

160

32
 Eligible Level 2B assets
 Weight assigned to other contractual inflows

164–165
 Scope of application of LCR and scope of consolidation of entities within a banking group

168–170
 Differences in home/host liquidity requirements due to national discretions
 Annex 2
 Principles for assessing eligibility for ALAs
 RCAP Jurisdictional Assessments Handbook

8.
 RCAP-SIB

8.1
 Scope
 The RCAP assessments of the Committee’s frameworks for G-SIBs and D-SIBs assess the completeness and consistency of domestic implementation with the Basel standards. The following Basel standards are used as reference for the RCAP-SIB assessments:
•
 Global systemically important banks: updated assessment methodology and the higher loss absorbency requirement (July 2013)

•
 G-SIB assessment reporting instructions (available at www.bis.org/bcbs/gsib/index.htm)
 In particular, the RCAP assessment of the Basel G-SIB framework covers the 12 provisions of the Basel G-SIB framework that should be implemented by jurisdictions. These cover: (i) reporting and public disclosure requirements; and (ii) the higher loss absorbency requirement and its composition and coordination with other regulatory requirements. The assessment assigns an overall grade for G-SIB implementation and for the two components of the G-SIB regime shown in Table 7.
 Graded components of the Basel G-SIB framework
 Table 7
 Higher loss absorbency Disclosure requirements
 The implementation of the Basel D-SIB framework 21 by member jurisdictions is not formally assessed on a graded basis. Instead, the Assessment Team collects information on the implementation of the D-SIB standards in the assessed member jurisdictions, which is used for a qualitative narrative. This approach is broadly consistent with the Committee’s objectives; while the Committee collects valuable information on implementation, a narrative respects the high-level, principles-based nature of the D-SIB framework. However, it is not necessarily as stringent as other RCAP exercises, due to the lack of grading.

8.2
 Design
 The assessment is carried out on a cross-jurisdictional basis. It is designed so that most of the work is based on off-site analysis. At the time of the first RCAP-SIB (2016), five Committee member jurisdictions had G-SIBs. 22 Initially, only these jurisdictions are subject to a formal RCAP-SIB assessment. A single Assessment Team, comprising four experts in addition to the Team Leader, assesses these five jurisdictions. When a jurisdiction has implemented the full G-SIB requirements but has no designated G-SIB, it can also volunteer for such an assessment. However, in this case, the assessment will not be graded. If a jurisdiction has a bank that becomes a designated G-SIB, it will become subject to an assessment of the G-SIB framework. In this context, the Basel G-SIB framework provides some leeway for jurisdictions as banks are required to meet the additional requirement within 12 months after progressing to a higher bucket.

21
 A framework for dealing with domestic systemically important banks – final document, Basel Committee on Banking Supervision, October 2012, www.bis.org/publ/bcbs233.htm.

22
 Based on the November 2015 G-SIB list (www.fsb.org/2015/11/fsb-publishes-the-2015-update-of-the-g-sib-list/), China, seven European Union countries (France, Germany, Italy, the Netherlands, Spain, Sweden and the United Kingdom), Japan, Switzerland and the United States were home to G-SIBs.
 RCAP Jurisdictional Assessments Handbook

33

Jurisdictions with banks in the G-SIB sample, but without designated G-SIBs, will report the status of adoption (timeliness and completeness) of the G-SIB reporting and disclosure standards as part of the half-yearly RCAP monitoring exercise. These member jurisdictions will not be assessed for any of the GSIB requirements. If a jurisdiction has a bank that exceeds the €200 billion threshold, or includes a bank in the sample based on its supervisory judgment, it will become subject to monitoring of the adoption status of reporting and disclosure requirements. With respect to the D-SIB framework, Basel Committee member jurisdictions are requested to complete a short questionnaire to collect information in a systematic way. The first such review of the DSIB framework is done in parallel with the first G-SIB assessment on a cross-jurisdictional basis (covering those jurisdictions with G-SIBs). Following the RCAP D-SIB assessment and a review of the experience, the scope, coverage, and assessment methodology for D-SIBs will be further discussed. The semiannual RCAP monitoring exercise will meanwhile continue to collect information on members’ implementation of D-SIB frameworks.

8.3
 Methodological considerations specific to the RCAP-SIB
 The RCAP assessment methodology set out in Section 3 should generally be followed for the assessment of the G-SIB framework. However, the concept of materiality is wider in the context of the RCAP-SIB. Implementation of the D-SIB framework is not formally assessed or graded, so the assessment methodology does not apply. In the case of the G-SIB framework, a distinction must be made between the identification of GSIBs and the consequences (ie the requirements for banks that are designated G-SIBs). For the identification part, the aim is to assess whether the national implementation ensures that the 12 indicators are reported and disclosed by banks as per the agreed Basel instructions and that the data submission is of high quality. Therefore, in their self-assessment, jurisdictions should indicate how they have implemented the reporting and disclosure requirements for each of the 12 indicators. To support the assessment, additional questions regarding the implementation and enforcement of the reporting instructions are included in the self-assessment questionnaire. The Assessment Team does not do a lineby-line assessment of the G-SIB reporting instructions (which aim at collecting the data necessary to assess the systemic importance of banks). However, based on a review of the responses from assessed jurisdictions to the self-assessment questionnaire, the Assessment Team may discuss the implementation of the reporting instructions with the jurisdictions in greater detail, so as to gain sufficient comfort that the reporting instructions are applied fully and consistently and that the data submitted to the Basel Committee Secretariat are of high quality. For the consequences part (ie higher loss absorbency), jurisdictions are free to be more conservative than prescribed by the Basel framework. In this case, areas of super-equivalence are noted in the assessment report, as is done for other RCAP assessments. For quantifiable deviations from the G-SIB framework, the impact is measured with the help of data publicly available or submitted by the supervisor (only when needed). In the event that a deviation affects the calculation of G-SIB scores, the Assessment Team will need to consider whether the impact of regulatory deviations may affect the ranking of banks and thus the capital requirements in other jurisdictions and not just the jurisdiction being assessed. The concept of impact and materiality for the G-SIB assessment is therefore wider than under the RCAP-Capital assessments. Assessors need to apply judgment when assessing the materiality of deviations. In all cases, the team should justify the materiality assessment and provide a clear rationale for the materiality assessment. In addition, the team will apply expert judgment to estimate the (potential) impact of deviations on the calculation of scores and take into account the broader interactions when assessing materiality.

34
 RCAP Jurisdictional Assessments Handbook

8.4
 Report
 RCAP-SIB reports include the following annexes in addition to those listed in Section 3.9.
•
 Financial indicators on the G-SIBs and the banking system in the assessed jurisdiction

•
 A summary of the Pillar 2 supervisory review process applied to G-SIBs and D-SIBs
 RCAP Jurisdictional Assessments Handbook

35

9.
 RCAP-NSFR

9.1
 Scope
 The RCAP-NSFR assessments cover the implementation of the Basel NSFR calculation and minimum requirement and the related disclosure standards. The following Basel standards (including any applicable annexes) are in the scope of the assessment:
•
 Basel III: the net stable funding ratio (October 2014)

•
 Pillar 3 disclosure requirements – consolidated and enhanced framework (March 2017), NSFR disclosures only

•
 Implementation of net stable funding ratio and treatment of derivative liabilities (October 2017)

•
 FAQs published by the Committee on the standards above, including those that would solve any interpretative issue arising during the assessment
 The assessment covers four components, as listed in Table 8. Assessed jurisdictions receive a grade for each of these components as well as an overall grade.
 Graded components of the Basel NSFR framework
 Table 8
 Scope, minimum requirement and application issues Available stable funding (numerator) Required stable funding (denominator) NSFR disclosure requirements
 The scope of the RCAP-NSFR assessments will also include all items listed for follow-up in previous RCAP-LCR assessments (see Section 5.2.1).

9.2
 Design
 The RCAP-NSFR assessments are designed as jurisdictional assessments ie peer reviews undertaken by technical experts reviewing the implementation in a single jurisdiction. The assessments will be conducted alongside the RCAP assessments on large exposures (see Section 10). Teams will typically comprise three or four assessors, in addition to the Team Leader. These assessments will cover all Basel Committee member jurisdictions.

9.3
 Methodological considerations specific to the RCAP-NSFR
 In general, the RCAP-NSFR assessments should be conducted in line with the methodology set out in Section 3. This includes the approach to classifying deviations, consideration of both quantitative impact and qualitative factors, the grades assigned and the grading approach. Like the LCR, the NSFR is a standardised approach based on a predefined weighting scheme. This affects the assessment of its implementation. First, it makes the assessment of regulatory consistency more tangible as compared with the assessment of modelled approaches. Second, any deviation from the Basel requirements will affect the mapping of assets and liabilities into NSFR categories and the application of available and required stable funding factors.

36
 RCAP Jurisdictional Assessments Handbook

9.4
 Report
 In addition to those listed in Section 3.9, the RCAP-NSFR report will contain the following annexes:
•
 Key liquidity indicators of the banking system and the sample banks in the assessed jurisdiction

•
 Implementation of elements of the NSFR subject to national discretion (Table 9)
 Elements left to national discretion Basel paragraph
25(a)
31
 Table 9 Description
 Treatment of deposits between banks within the same cooperative network Treatment of excess collateral in a covered bond collateral pool allowing for multiple issuance Treatment of central bank operations, eg

31, 36

•
 Required stable funding (RSF) factor for required reserves

•
 RSF for assets encumbered for exceptional liquidity operations

•
 Treatment of derivative transactions with central banks arising from short-term monetary policy and liquidity operations

43
 RSF factor for derivative liabilities

45
 Treatment of interdependent assets and liabilities

47
 RSF factors for other contingent funding obligations

50
 Scope of application of NSFR and scope of consolidation of entities within a banking group
 RCAP Jurisdictional Assessments Handbook

37

10.
 RCAP-Large exposures

10.1
 Scope
 The RCAP assessments of the large exposures framework (RCAP-LEX) assess the completeness and consistency of domestic frameworks with the Basel standards. The following standards (including any applicable annexes) are in the scope of the assessment:
•
 Supervisory framework for measuring and controlling large exposures (April 2014)

•
 FAQs published by the Committee on the standards above, including those that would solve any interpretative issue arising during the assessment (see Section 2.4 for more on the use of FAQs)
 The assessment covers three components, as listed in Table 10. Assessed jurisdictions receive a grade for each of these components as well as an overall grade.
 Graded components of the Basel large exposures framework
 Table 10
 Scope and definitions Minimum requirements and transitional arrangements Value of exposures

10.2
 Design
 The RCAP-LEX assessments are designed as jurisdictional assessments, ie peer reviews, undertaken by technical experts reviewing the implementation in a single jurisdiction. The assessments will be conducted alongside the RCAP-NSFR assessments (see Section 9). Teams will typically comprise three or four assessors, in addition to the Team Leader. These assessments will cover all Basel Committee member jurisdictions.

10.3
 Methodological considerations specific to RCAP-LEX
 In general, the RCAP-LEX assessments should be conducted in line with the methodology set out in Section
3. This includes the approach to classifying deviations, consideration of both quantitative impact and qualitative factors, the grades assigned and the grading approach. A key part of the assessment is based on the requirement of the large exposures framework that banks provide to supervisors a list of their largest 20 counterparties. 23 These 20 largest counterparties should be identified after the application of credit risk mitigation techniques and irrespective of the values of these exposures relative to the bank’s eligible capital base. The Assessment Team, in coordination with the jurisdiction being assessed, will identify a sample of banks according to the methodology set out in Section 2.4. The Assessment Team will request from the supervisor the list of the largest 20 non-exempted counterparties for each sample bank. Each large exposure is defined as the sum of all exposure values of a bank to a counterparty or to a group of

23

38
 Although exempted large exposures should be reported to supervisors in line with the large exposures framework, the RCAP materiality assessment will be made only on the non-exempted large exposures. See Section II, 15(iv) and Section IV of the Basel large exposures framework for more information, www.bis.org/publ/bcbs283.pdf.
 RCAP Jurisdictional Assessments Handbook

connected counterparties. The large exposure ratio is the large exposure as a percentage of the bank’s eligible capital base.

10.4
 Report
 RCAP-LEX reports do not include any annexes in addition to those listed in Section 3.9.
 RCAP Jurisdictional Assessments Handbook

39


